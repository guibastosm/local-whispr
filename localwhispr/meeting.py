"""Meeting recording with dual capture (mic + monitor) via PipeWire."""

from __future__ import annotations

import signal
import subprocess
import time
import wave
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

import numpy as np

if TYPE_CHECKING:
    from localwhispr.config import MeetingConfig


@dataclass
class MeetingFiles:
    """Paths of files generated by a meeting recording."""
    output_dir: Path
    mic_wav: Path
    system_wav: Path
    combined_wav: Path
    started_at: datetime
    duration_seconds: float


def detect_sources() -> dict[str, str]:
    """Automatically detect mic and monitor sources via pactl.

    Prioritizes USB devices (headsets) over HDMI/built-in.
    """
    sources: dict[str, str] = {"mic": "", "monitor": ""}

    try:
        result = subprocess.run(
            ["pactl", "list", "short", "sources"],
            capture_output=True, text=True, timeout=5,
        )
        if result.returncode != 0:
            return sources

        monitors: list[str] = []
        mics: list[str] = []

        for line in result.stdout.strip().splitlines():
            parts = line.split("\t")
            if len(parts) < 2:
                continue
            name = parts[1]

            if name.endswith(".monitor"):
                monitors.append(name)
            elif "input" in name and not name.endswith(".monitor"):
                mics.append(name)

        # Prioritize USB (headsets) over HDMI/PCI (built-in/GPU)
        def _is_usb(name: str) -> bool:
            return ".usb-" in name or ".usb_" in name

        # Monitor: prefer USB, otherwise pick the first
        usb_monitors = [m for m in monitors if _is_usb(m)]
        sources["monitor"] = usb_monitors[0] if usb_monitors else (monitors[0] if monitors else "")

        # Mic: prefer USB, otherwise pick the first
        usb_mics = [m for m in mics if _is_usb(m)]
        sources["mic"] = usb_mics[0] if usb_mics else (mics[0] if mics else "")

        if monitors:
            print(f"[localwhispr] Available monitors: {monitors}")
            print(f"[localwhispr] Selected monitor: {sources['monitor']}")
        if mics:
            print(f"[localwhispr] Available mics: {mics}")
            print(f"[localwhispr] Selected mic: {sources['mic']}")

    except Exception as e:
        print(f"[localwhispr] WARNING: failed to detect sources: {e}")

    return sources


class MeetingRecorder:
    """Records meetings by capturing mic + monitor via pw-record (PipeWire)."""

    def __init__(self, config: MeetingConfig | None = None) -> None:
        from localwhispr.config import MeetingConfig as MC

        cfg = config or MC()
        self._output_base = Path(cfg.output_dir).expanduser()
        self._sample_rate = cfg.sample_rate
        self._mic_source = cfg.mic_source
        self._monitor_source = cfg.monitor_source

        self._mic_proc: subprocess.Popen | None = None
        self._monitor_proc: subprocess.Popen | None = None
        self._output_dir: Path | None = None
        self._mic_path: Path | None = None
        self._monitor_path: Path | None = None
        self._started_at: datetime | None = None
        self._recording = False

    @property
    def is_recording(self) -> bool:
        return self._recording

    def start(self) -> Path:
        """Start dual recording. Returns the output directory."""
        if self._recording:
            raise RuntimeError("Already recording")

        # Resolve sources
        mic_src = self._mic_source
        monitor_src = self._monitor_source

        if mic_src == "auto" or monitor_src == "auto":
            detected = detect_sources()
            if mic_src == "auto":
                mic_src = detected["mic"]
            if monitor_src == "auto":
                monitor_src = detected["monitor"]

        if not mic_src:
            raise RuntimeError(
                "No microphone detected. Configure 'mic_source' in config.yaml"
            )
        if not monitor_src:
            raise RuntimeError(
                "No monitor source detected. Configure 'monitor_source' in config.yaml"
            )

        print(f"[localwhispr] Mic source:     {mic_src}")
        print(f"[localwhispr] Monitor source: {monitor_src}")

        # Create output directory
        self._started_at = datetime.now()
        ts = self._started_at.strftime("%Y-%m-%d_%H-%M")
        self._output_dir = self._output_base / ts
        self._output_dir.mkdir(parents=True, exist_ok=True)

        self._mic_path = self._output_dir / "mic.wav"
        self._monitor_path = self._output_dir / "system.wav"

        # Start pw-record for mic (native sample rate, convert later)
        self._mic_proc = subprocess.Popen(
            [
                "pw-record",
                "--target", mic_src,
                str(self._mic_path),
            ],
            stdin=subprocess.DEVNULL,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE,
        )

        # Start parecord for monitor (pw-record --target doesn't connect to monitors)
        self._monitor_proc = subprocess.Popen(
            [
                "parecord",
                "--device", monitor_src,
                "--file-format=wav",
                str(self._monitor_path),
            ],
            stdin=subprocess.DEVNULL,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE,
        )

        self._recording = True
        print(f"[localwhispr] Recording meeting in: {self._output_dir}")
        return self._output_dir

    def stop(self) -> MeetingFiles | None:
        """Stop recording and return generated files."""
        if not self._recording:
            return None

        self._recording = False
        duration = (datetime.now() - self._started_at).total_seconds() if self._started_at else 0

        # Stop pw-record/parecord processes with SIGINT (to close WAV correctly)
        for name, proc in [("mic", self._mic_proc), ("monitor", self._monitor_proc)]:
            if proc and proc.poll() is None:
                try:
                    proc.send_signal(signal.SIGINT)
                    proc.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    proc.terminate()
                    try:
                        proc.wait(timeout=3)
                    except subprocess.TimeoutExpired:
                        proc.kill()
                except Exception as e:
                    print(f"[localwhispr] WARNING: error stopping {name}: {e}")

        self._mic_proc = None
        self._monitor_proc = None

        # Check if files exist and have content
        if not self._mic_path or not self._monitor_path:
            return None

        for p in [self._mic_path, self._monitor_path]:
            if not p.exists():
                print(f"[localwhispr] WARNING: file not found: {p}")
            else:
                size_kb = p.stat().st_size / 1024
                print(f"[localwhispr] {p.name}: {size_kb:.1f} KB")

        # Mix both channels
        combined_path = self._output_dir / "combined.wav"
        self._mix_audio(self._mic_path, self._monitor_path, combined_path)

        print(f"[localwhispr] Recording finished ({duration:.0f}s)")

        return MeetingFiles(
            output_dir=self._output_dir,
            mic_wav=self._mic_path,
            system_wav=self._monitor_path,
            combined_wav=combined_path,
            started_at=self._started_at,
            duration_seconds=duration,
        )

    def _mix_audio(self, mic_path: Path, monitor_path: Path, output_path: Path) -> None:
        """Combine mic + monitor into a single mono 16kHz WAV."""
        try:
            mic_data = self._read_wav_as_mono_16k(mic_path)
            monitor_data = self._read_wav_as_mono_16k(monitor_path)

            if mic_data is None and monitor_data is None:
                print("[localwhispr] WARNING: no audio to mix")
                return

            # If only one is available, use it
            if mic_data is None:
                combined = monitor_data
            elif monitor_data is None:
                combined = mic_data
            else:
                # Equalize lengths (pad the shorter one with silence)
                max_len = max(len(mic_data), len(monitor_data))
                mic_padded = np.pad(mic_data, (0, max_len - len(mic_data)))
                mon_padded = np.pad(monitor_data, (0, max_len - len(monitor_data)))

                # Mix: average of both channels (avoids clipping)
                combined = ((mic_padded.astype(np.int32) + mon_padded.astype(np.int32)) // 2).astype(np.int16)

            # Save combined WAV (mono, 16kHz, s16)
            with wave.open(str(output_path), "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(self._sample_rate)
                wf.writeframes(combined.tobytes())

            size_kb = output_path.stat().st_size / 1024
            print(f"[localwhispr] combined.wav: {size_kb:.1f} KB ({len(combined)/self._sample_rate:.0f}s)")

        except Exception as e:
            print(f"[localwhispr] ERROR mixing audio: {e}")

    def _read_wav_as_mono_16k(self, path: Path) -> np.ndarray | None:
        """Read WAV, convert to mono 16kHz int16."""
        if not path.exists() or path.stat().st_size < 100:
            return None
        try:
            with wave.open(str(path), "rb") as wf:
                n_channels = wf.getnchannels()
                sample_rate = wf.getframerate()
                sample_width = wf.getsampwidth()
                n_frames = wf.getnframes()
                raw = wf.readframes(n_frames)

            print(f"[localwhispr] {path.name}: {n_channels}ch {sample_rate}Hz {sample_width*8}bit {n_frames} frames")

            # Convert to int16 (if s32, reduce)
            if sample_width == 4:
                data = np.frombuffer(raw, dtype=np.int32)
                data = (data >> 16).astype(np.int16)
            elif sample_width == 2:
                data = np.frombuffer(raw, dtype=np.int16)
            else:
                print(f"[localwhispr] WARNING: sample_width={sample_width} not supported")
                return None

            # Convert to mono (average channels)
            if n_channels > 1:
                data = data.reshape(-1, n_channels).mean(axis=1).astype(np.int16)

            # Resample to 16kHz if needed
            if sample_rate != self._sample_rate:
                # Simple resampling via linear interpolation
                duration = len(data) / sample_rate
                target_len = int(duration * self._sample_rate)
                indices = np.linspace(0, len(data) - 1, target_len)
                data = np.interp(indices, np.arange(len(data)), data.astype(np.float64)).astype(np.int16)

            rms = np.sqrt(np.mean(data.astype(np.float64)**2))
            print(f"[localwhispr] {path.name} â†’ mono 16kHz: {len(data)} samples, RMS={rms:.1f}")
            return data

        except Exception as e:
            print(f"[localwhispr] WARNING: error reading {path.name}: {e}")
            return None
